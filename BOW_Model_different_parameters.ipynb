{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1316, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adm_notes_exclude_dead_readm_updated.csv\",\n",
    "                     header=0)\n",
    "df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1161\n",
       "1     155\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['label'] = (df['redays']<=30).astype('int')\n",
    "data['summary'] = df['summary']\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1146\n",
       "1     154\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dropna=data.dropna()\n",
    "data_dropna['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # This function preprocesses the text by filling not a number and replacing new lines ('\\n') and carriage returns ('\\r')\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    df.TEXT =df.TEXT.str.replace('\\n',' ')\n",
    "    df.TEXT =df.TEXT.str.replace('\\r',' ')\n",
    "    return df\n",
    "\n",
    "def tokenizer_better(text):\n",
    "    # tokenize the text by replacing punctuation and numbers with spaces and lowercase all words\n",
    "    punc_list = string.punctuation+'0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.lower().translate(t)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "my_stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    "                 'is','patient','s','he','at','as','or','one','she','his','her','am',\n",
    "                 'were','you','pt','pm','by','be','had','your','this','date',\n",
    "                'from','there','an','that','p','are','have','has','h','but','o',\n",
    "                'namepattern','which','every','also','t','that']\n",
    "\n",
    "\n",
    "# vect = CountVectorizer(max_features = 3000, tokenizer = tokenizer_better, stop_words = my_stop_words)\n",
    "# # this could take a while\n",
    "# data_dropna['x_input'] = vect.fit_transform(data_dropna['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify the dataset into training and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_dropna['summary'], data_dropna['label'], \n",
    "                                                    test_size=0.15, random_state=42,\n",
    "                                                    stratify = data_dropna['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'svm__C': 0.001, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.478 (+/-0.080) for {'svm__C': 0.001, 'svm__class_weight': 'balanced'}\n",
      "0.493 (+/-0.102) for {'svm__C': 0.001, 'svm__class_weight': None}\n",
      "0.500 (+/-0.116) for {'svm__C': 0.001, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.504 (+/-0.086) for {'svm__C': 0.001, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.474 (+/-0.048) for {'svm__C': 0.01, 'svm__class_weight': 'balanced'}\n",
      "0.474 (+/-0.046) for {'svm__C': 0.01, 'svm__class_weight': None}\n",
      "0.488 (+/-0.086) for {'svm__C': 0.01, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.474 (+/-0.069) for {'svm__C': 0.01, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.472 (+/-0.050) for {'svm__C': 0.1, 'svm__class_weight': 'balanced'}\n",
      "0.473 (+/-0.049) for {'svm__C': 0.1, 'svm__class_weight': None}\n",
      "0.472 (+/-0.040) for {'svm__C': 0.1, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.474 (+/-0.046) for {'svm__C': 0.1, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.471 (+/-0.054) for {'svm__C': 1, 'svm__class_weight': 'balanced'}\n",
      "0.471 (+/-0.054) for {'svm__C': 1, 'svm__class_weight': None}\n",
      "0.472 (+/-0.051) for {'svm__C': 1, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.471 (+/-0.051) for {'svm__C': 1, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       172\n",
      "           1       0.19      0.30      0.24        23\n",
      "\n",
      "    accuracy                           0.77       195\n",
      "   macro avg       0.55      0.57      0.55       195\n",
      "weighted avg       0.82      0.77      0.79       195\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'svm__C': 0.001, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.112 (+/-0.083) for {'svm__C': 0.001, 'svm__class_weight': 'balanced'}\n",
      "0.071 (+/-0.086) for {'svm__C': 0.001, 'svm__class_weight': None}\n",
      "0.000 (+/-0.000) for {'svm__C': 0.001, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.148 (+/-0.087) for {'svm__C': 0.001, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.105 (+/-0.077) for {'svm__C': 0.01, 'svm__class_weight': 'balanced'}\n",
      "0.083 (+/-0.047) for {'svm__C': 0.01, 'svm__class_weight': None}\n",
      "0.071 (+/-0.054) for {'svm__C': 0.01, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.112 (+/-0.083) for {'svm__C': 0.01, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.104 (+/-0.086) for {'svm__C': 0.1, 'svm__class_weight': 'balanced'}\n",
      "0.105 (+/-0.085) for {'svm__C': 0.1, 'svm__class_weight': None}\n",
      "0.108 (+/-0.032) for {'svm__C': 0.1, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.110 (+/-0.087) for {'svm__C': 0.1, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "0.107 (+/-0.080) for {'svm__C': 1, 'svm__class_weight': 'balanced'}\n",
      "0.107 (+/-0.080) for {'svm__C': 1, 'svm__class_weight': None}\n",
      "0.103 (+/-0.083) for {'svm__C': 1, 'svm__class_weight': {0: 0.86, 1: 0.14}}\n",
      "0.103 (+/-0.083) for {'svm__C': 1, 'svm__class_weight': {0: 0.1, 1: 0.9}}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       172\n",
      "           1       0.19      0.30      0.24        23\n",
      "\n",
      "    accuracy                           0.77       195\n",
      "   macro avg       0.55      0.57      0.55       195\n",
      "weighted avg       0.82      0.77      0.79       195\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn import svm\n",
    "\n",
    "#stratify X_train to training and validation dataset\n",
    "skf = StratifiedKFold(n_splits=5,random_state = 42)\n",
    "skf.get_n_splits(X_train, y_train)\n",
    "\n",
    "parameter_candidates = {\n",
    "  'svm__C': [0.001,0.01, 0.1, 1],\n",
    "  'svm__class_weight':['balanced',None, {0:0.86,1:0.14},{0:0.1,1:0.9}]}\n",
    "\n",
    "\n",
    "grid_param = {\n",
    "    'n_estimators': [100, 300, 500, 800, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "scores = ['roc_auc', 'f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    text_svm4 = Pipeline([\n",
    "         ('vect', CountVectorizer(lowercase = True, \n",
    "                                  max_features = 4000, \n",
    "                                  tokenizer = tokenizer_better,\n",
    "                                  stop_words =my_stop_words)),\n",
    "#          ('tfidf', TfidfTransformer()), #lower performs\n",
    "        # ('lg', LogisticRegression(max_iter=10000, tol=0.1)),#0.83\n",
    "         ('svm', LinearSVC(random_state=0))\n",
    "        ])\n",
    "    \n",
    "    search2= GridSearchCV(estimator=text_svm4, \n",
    "                          param_grid = parameter_candidates,\n",
    "                          cv = skf,\n",
    "                          scoring= score)\n",
    "    search2.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(search2.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = search2.cv_results_['mean_test_score']\n",
    "    stds = search2.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, search2.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search2.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
