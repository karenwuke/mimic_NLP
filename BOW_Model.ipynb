{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1394, 27)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adm_notes_exclude_dead_readm.csv\",\n",
    "                     header=0)\n",
    "df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1161\n",
       "1     233\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['label'] = (df['redays']<=30).astype('int')\n",
    "data['summary'] = df['summary']\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2183-3-23**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2139-9-8**]     Discharge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2146-11-17**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2146-12-22**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2199-9-1**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1389</td>\n",
       "      <td>0</td>\n",
       "      <td>[** **] Date:  [**2116-7-1**]              Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2109-6-16**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1391</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2126-2-20**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1392</td>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2117-4-13**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1393</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2188-12-10**]       Discha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1377 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            summary\n",
       "0         0  Admission Date:  [**2183-3-23**]              ...\n",
       "1         0  Admission Date:  [**2139-9-8**]     Discharge ...\n",
       "2         0  Admission Date:  [**2146-11-17**]             ...\n",
       "3         0  Admission Date:  [**2146-12-22**]             ...\n",
       "4         0  Admission Date:  [**2199-9-1**]              D...\n",
       "...     ...                                                ...\n",
       "1389      0  [** **] Date:  [**2116-7-1**]              Dis...\n",
       "1390      1  Admission Date:  [**2109-6-16**]              ...\n",
       "1391      0  Admission Date:  [**2126-2-20**]              ...\n",
       "1392      1  Admission Date:  [**2117-4-13**]              ...\n",
       "1393      0  Admission Date:  [**2188-12-10**]       Discha...\n",
       "\n",
       "[1377 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dropna=data.dropna()\n",
    "data_dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1146\n",
       "1     231\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dropna['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by class\n",
    "df_class_0 = data_dropna[data_dropna['label'] == 0]\n",
    "df_class_1 = data_dropna[data_dropna['label'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unbalanced dataset, so that we need up-sampling the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_upsample = df_class_1.sample(1146, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2292, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over = pd.concat([df_class_1_upsample, df_class_0], axis=0)\n",
    "df_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2124-10-18**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2184-9-14**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2150-2-9**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2140-8-12**]    Discharge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2138-4-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2287</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2159-4-27**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2288</td>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2178-6-26**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2289</td>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2118-3-5**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0</td>\n",
       "      <td>Admission Date:  [**2193-8-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2291</td>\n",
       "      <td>1</td>\n",
       "      <td>Admission Date:  [**2144-8-12**]       Dischar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            summary\n",
       "0         0  Admission Date:  [**2124-10-18**]             ...\n",
       "1         0  Admission Date:  [**2184-9-14**]       Dischar...\n",
       "2         0  Admission Date:  [**2150-2-9**]              D...\n",
       "3         0  Admission Date:  [**2140-8-12**]    Discharge ...\n",
       "4         0  Admission Date:  [**2138-4-21**]              ...\n",
       "...     ...                                                ...\n",
       "2287      0  Admission Date:  [**2159-4-27**]              ...\n",
       "2288      1  Admission Date:  [**2178-6-26**]              ...\n",
       "2289      1  Admission Date:  [**2118-3-5**]              D...\n",
       "2290      0  Admission Date:  [**2193-8-10**]              ...\n",
       "2291      1  Admission Date:  [**2144-8-12**]       Dischar...\n",
       "\n",
       "[2292 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the order of training samples \n",
    "df_all = df_over.sample(n = 2292, random_state = 42).reset_index(drop = True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_all['summary'],df_all['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Step2: Process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # This function preprocesses the text by filling not a number and replacing new lines ('\\n') and carriage returns ('\\r')\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    df.TEXT =df.TEXT.str.replace('\\n',' ')\n",
    "    df.TEXT =df.TEXT.str.replace('\\r',' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Admission Date:  [**2124-10-18**]             ...\n",
       "1       Admission Date:  [**2184-9-14**]       Dischar...\n",
       "2       Admission Date:  [**2150-2-9**]              D...\n",
       "3       Admission Date:  [**2140-8-12**]    Discharge ...\n",
       "4       Admission Date:  [**2138-4-21**]              ...\n",
       "                              ...                        \n",
       "2287    Admission Date:  [**2159-4-27**]              ...\n",
       "2288    Admission Date:  [**2178-6-26**]              ...\n",
       "2289    Admission Date:  [**2118-3-5**]              D...\n",
       "2290    Admission Date:  [**2193-8-10**]              ...\n",
       "2291    Admission Date:  [**2144-8-12**]       Dischar...\n",
       "Name: summary, Length: 2292, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = preprocess_text(df_all['summary'])\n",
    "df_all['summary'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'should',\n",
       " 'be',\n",
       " 'tokenized',\n",
       " '.',\n",
       " '02/02/2018',\n",
       " 'sentence',\n",
       " 'has',\n",
       " 'stars**']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to split text into word\n",
    "word_tokenize('This should be tokenized. 02/02/2018 sentence has stars**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_better(text):\n",
    "    # tokenize the text by replacing punctuation and numbers with spaces and lowercase all words\n",
    "    punc_list = string.punctuation+'0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.lower().translate(t)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'should', 'be', 'tokenized', 'sentence', 'has', 'stars']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_better('This should be tokenized. 02/02/2018 sentence has stars**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sample_text = ['Data science is about the data', 'The science is amazing', 'Predictive modeling is part of data science']\n",
    "\n",
    "vect = CountVectorizer(tokenizer = tokenizer_better)\n",
    "vect.fit(sample_text)\n",
    "\n",
    "# matrix is stored as a sparse matrix (since you have a lot of zeros)\n",
    "X = vect.transform(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'amazing',\n",
       " 'data',\n",
       " 'is',\n",
       " 'modeling',\n",
       " 'of',\n",
       " 'part',\n",
       " 'predictive',\n",
       " 'science',\n",
       " 'the']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the column names\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get another example from clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aado',\n",
       " 'abdomen',\n",
       " 'abg',\n",
       " 'abnormalities',\n",
       " 'above',\n",
       " 'absense',\n",
       " 'acetaminophen',\n",
       " 'acute',\n",
       " 'admission',\n",
       " 'admitted',\n",
       " 'afib',\n",
       " 'after',\n",
       " 'ago',\n",
       " 'allergies',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alternating',\n",
       " 'ampicillin',\n",
       " 'anemia',\n",
       " 'angap',\n",
       " 'anteriorly',\n",
       " 'anterolisthesis',\n",
       " 'anticoagulation',\n",
       " 'any',\n",
       " 'aortic',\n",
       " 'apex',\n",
       " 'apnea',\n",
       " 'appear',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arousable',\n",
       " 'artery',\n",
       " 'asa',\n",
       " 'asleep',\n",
       " 'assessed',\n",
       " 'atelectasis',\n",
       " 'atraumatic',\n",
       " 'atrial',\n",
       " 'attending',\n",
       " 'awake',\n",
       " 'axilla',\n",
       " 'b',\n",
       " 'bacteri',\n",
       " 'base',\n",
       " 'based',\n",
       " 'baso',\n",
       " 'began',\n",
       " 'bid',\n",
       " 'bilateral',\n",
       " 'bilaterally',\n",
       " 'bilirub',\n",
       " 'bladder',\n",
       " 'bleed',\n",
       " 'bleeds',\n",
       " 'blood',\n",
       " 'blowing',\n",
       " 'both',\n",
       " 'bowel',\n",
       " 'bp',\n",
       " 'bps',\n",
       " 'brain',\n",
       " 'breath',\n",
       " 'breathing',\n",
       " 'brief',\n",
       " 'brought',\n",
       " 'building',\n",
       " 'bulk',\n",
       " 'c',\n",
       " 'calcium',\n",
       " 'call',\n",
       " 'caltco',\n",
       " 'came',\n",
       " 'can',\n",
       " 'capsule',\n",
       " 'cardiac',\n",
       " 'cardiologist',\n",
       " 'cardiology',\n",
       " 'cardiomegaly',\n",
       " 'care',\n",
       " 'cat',\n",
       " 'center',\n",
       " 'cerebral',\n",
       " 'chair',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'chest',\n",
       " 'chief',\n",
       " 'chills',\n",
       " 'chloride',\n",
       " 'chronicity',\n",
       " 'cl',\n",
       " 'clear',\n",
       " 'clinical',\n",
       " 'clinically',\n",
       " 'close',\n",
       " 'closely',\n",
       " 'cm',\n",
       " 'color',\n",
       " 'compared',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'component',\n",
       " 'concern',\n",
       " 'concerning',\n",
       " 'condition',\n",
       " 'conjunctival',\n",
       " 'consciousness',\n",
       " 'constipation',\n",
       " 'consulted',\n",
       " 'continued',\n",
       " 'convexity',\n",
       " 'cooks',\n",
       " 'cord',\n",
       " 'correlation',\n",
       " 'could',\n",
       " 'coumadin',\n",
       " 'course',\n",
       " 'cranial',\n",
       " 'creat',\n",
       " 'ct',\n",
       " 'cx',\n",
       " 'cxr',\n",
       " 'cyst',\n",
       " 'daily',\n",
       " 'data',\n",
       " 'day',\n",
       " 'days',\n",
       " 'decided',\n",
       " 'dedicated',\n",
       " 'deferred',\n",
       " 'degenerative',\n",
       " 'delt',\n",
       " 'denied',\n",
       " 'department',\n",
       " 'depressed',\n",
       " 'described',\n",
       " 'determined',\n",
       " 'dhs',\n",
       " 'diagnosis',\n",
       " 'diastolic',\n",
       " 'did',\n",
       " 'difficulty',\n",
       " 'dilated',\n",
       " 'diltiazem',\n",
       " 'discharge',\n",
       " 'discontinue',\n",
       " 'discussion',\n",
       " 'disease',\n",
       " 'disposition',\n",
       " 'diuresis',\n",
       " 'djd',\n",
       " 'docusate',\n",
       " 'doppler',\n",
       " 'dose',\n",
       " 'downgoing',\n",
       " 'dr',\n",
       " 'dressed',\n",
       " 'drift',\n",
       " 'driving',\n",
       " 'drugs',\n",
       " 'dry',\n",
       " 'dvt',\n",
       " 'dysfunction',\n",
       " 'ecchymoses',\n",
       " 'echo',\n",
       " 'ed',\n",
       " 'edema',\n",
       " 'effect',\n",
       " 'effusion',\n",
       " 'elevation',\n",
       " 'emergency',\n",
       " 'enterococcus',\n",
       " 'eomi',\n",
       " 'eos',\n",
       " 'epi',\n",
       " 'episode',\n",
       " 'etoh',\n",
       " 'evaluated',\n",
       " 'evaluation',\n",
       " 'evidence',\n",
       " 'evlauation',\n",
       " 'exam',\n",
       " 'examination',\n",
       " 'excluded',\n",
       " 'expanding',\n",
       " 'experience',\n",
       " 'explain',\n",
       " 'extended',\n",
       " 'extent',\n",
       " 'extraaxial',\n",
       " 'extremities',\n",
       " 'facial',\n",
       " 'facility',\n",
       " 'family',\n",
       " 'fasciculations',\n",
       " 'fax',\n",
       " 'feel',\n",
       " 'fell',\n",
       " 'felt',\n",
       " 'fever',\n",
       " 'fevers',\n",
       " 'ffp',\n",
       " 'fh',\n",
       " 'fibrillation',\n",
       " 'first',\n",
       " 'floor',\n",
       " 'fluent',\n",
       " 'flush',\n",
       " 'foci',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'followup',\n",
       " 'found',\n",
       " 'fracture',\n",
       " 'frontal',\n",
       " 'function',\n",
       " 'further',\n",
       " 'general',\n",
       " 'generalized',\n",
       " 'given',\n",
       " 'glass',\n",
       " 'global',\n",
       " 'glucose',\n",
       " 'good',\n",
       " 'grade',\n",
       " 'ground',\n",
       " 'growth',\n",
       " 'ham',\n",
       " 'hammock',\n",
       " 'having',\n",
       " 'hazy',\n",
       " 'hco',\n",
       " 'hct',\n",
       " 'head',\n",
       " 'headache',\n",
       " 'heent',\n",
       " 'helpful',\n",
       " 'hematomas',\n",
       " 'hemi',\n",
       " 'hemineglect',\n",
       " 'hemolyzed',\n",
       " 'hemorrhage',\n",
       " 'hemorrhages',\n",
       " 'hemorrhagic',\n",
       " 'hgb',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'history',\n",
       " 'hold',\n",
       " 'holosystolic',\n",
       " 'horns',\n",
       " 'hospital',\n",
       " 'hours',\n",
       " 'however',\n",
       " 'hr',\n",
       " 'hsm',\n",
       " 'htn',\n",
       " 'hypertension',\n",
       " 'hypertrophy',\n",
       " 'i',\n",
       " 'icterus',\n",
       " 'icu',\n",
       " 'identified',\n",
       " 'if',\n",
       " 'ii',\n",
       " 'iii',\n",
       " 'iliac',\n",
       " 'illness',\n",
       " 'imaging',\n",
       " 'immediately',\n",
       " 'improved',\n",
       " 'inadequately',\n",
       " 'incontinence',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'indenting',\n",
       " 'indeterminate',\n",
       " 'indicated',\n",
       " 'infarct',\n",
       " 'infarcts',\n",
       " 'infection',\n",
       " 'initial',\n",
       " 'initially',\n",
       " 'injury',\n",
       " 'inr',\n",
       " 'insterstitial',\n",
       " 'instructions',\n",
       " 'intact',\n",
       " 'interstitial',\n",
       " 'interval',\n",
       " 'intervention',\n",
       " 'intraperitoneal',\n",
       " 'intraventricular',\n",
       " 'invasive',\n",
       " 'ip',\n",
       " 'iph',\n",
       " 'irregular',\n",
       " 'it',\n",
       " 'iv',\n",
       " 'ix',\n",
       " 'jvp',\n",
       " 'k',\n",
       " 'keppra',\n",
       " 'ketone',\n",
       " 'knee',\n",
       " 'known',\n",
       " 'l',\n",
       " 'laboratory',\n",
       " 'labs',\n",
       " 'large',\n",
       " 'lasix',\n",
       " 'last',\n",
       " 'lastname',\n",
       " 'lateral',\n",
       " 'layering',\n",
       " 'left',\n",
       " 'lesion',\n",
       " 'lesions',\n",
       " 'leukocytosis',\n",
       " 'leuks',\n",
       " 'level',\n",
       " 'levetiracetam',\n",
       " 'lf',\n",
       " 'ligamentous',\n",
       " 'light',\n",
       " 'likely',\n",
       " 'limitation',\n",
       " 'line',\n",
       " 'liquor',\n",
       " 'lives',\n",
       " 'lnc',\n",
       " 'lobe',\n",
       " 'location',\n",
       " 'longer',\n",
       " 'loss',\n",
       " 'lung',\n",
       " 'lungs',\n",
       " 'lymphs',\n",
       " 'made',\n",
       " 'maintaining',\n",
       " 'major',\n",
       " 'male',\n",
       " 'management',\n",
       " 'managment',\n",
       " 'max',\n",
       " 'may',\n",
       " 'mcv',\n",
       " 'md',\n",
       " 'medical',\n",
       " 'medication',\n",
       " 'medications',\n",
       " 'medicine',\n",
       " 'meeting',\n",
       " 'mental',\n",
       " 'metoprolol',\n",
       " 'mg',\n",
       " 'microbiology',\n",
       " 'micu',\n",
       " 'midline',\n",
       " 'mild',\n",
       " 'mildly',\n",
       " 'ml',\n",
       " 'mm',\n",
       " 'mod',\n",
       " 'moderate',\n",
       " 'moderately',\n",
       " 'monitored',\n",
       " 'monos',\n",
       " 'month',\n",
       " 'months',\n",
       " 'most',\n",
       " 'motor',\n",
       " 'mouth',\n",
       " 'mr',\n",
       " 'mri',\n",
       " 'multilevel',\n",
       " 'murmur',\n",
       " 'na',\n",
       " 'nabs',\n",
       " 'nad',\n",
       " 'nameis',\n",
       " 'naming',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'neg',\n",
       " 'negative',\n",
       " 'neglect',\n",
       " 'neighbor',\n",
       " 'nerves',\n",
       " 'neuro',\n",
       " 'neurological',\n",
       " 'neurology',\n",
       " 'neurosurgery',\n",
       " 'neuts',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nitrite',\n",
       " 'nitrofurantoin',\n",
       " 'no',\n",
       " 'none',\n",
       " 'normal',\n",
       " 'normally',\n",
       " 'normocephalic',\n",
       " 'not',\n",
       " 'notable',\n",
       " 'noted',\n",
       " 'ns',\n",
       " 'nsg',\n",
       " 'nt',\n",
       " 'nursing',\n",
       " 'nystagmus',\n",
       " 'obtained',\n",
       " 'occ',\n",
       " 'occasional',\n",
       " 'occipital',\n",
       " 'only',\n",
       " 'opacity',\n",
       " 'osh',\n",
       " 'osteoarthritis',\n",
       " 'osteopenia',\n",
       " 'other',\n",
       " 'out',\n",
       " 'outpatient',\n",
       " 'overload',\n",
       " 'owner',\n",
       " 'pain',\n",
       " 'palatal',\n",
       " 'pallor',\n",
       " 'paraphasias',\n",
       " 'parietal',\n",
       " 'part',\n",
       " 'past',\n",
       " 'pattern',\n",
       " 'pco',\n",
       " 'per',\n",
       " 'periods',\n",
       " 'peripheral',\n",
       " 'perrl',\n",
       " 'pertinent',\n",
       " 'pf',\n",
       " 'ph',\n",
       " 'phone',\n",
       " 'phoned',\n",
       " 'phonemic',\n",
       " 'phos',\n",
       " 'physical',\n",
       " 'physician',\n",
       " 'pick',\n",
       " 'pinprick',\n",
       " 'please',\n",
       " 'pleasure',\n",
       " 'pleural',\n",
       " 'plt',\n",
       " 'pmhx',\n",
       " 'po',\n",
       " 'positive',\n",
       " 'present',\n",
       " 'prevent',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'primary',\n",
       " 'prn',\n",
       " 'procedure',\n",
       " 'products',\n",
       " 'progression',\n",
       " 'pronator',\n",
       " 'prophylaxis',\n",
       " 'protein',\n",
       " 'provide',\n",
       " 'provider',\n",
       " 'ptt',\n",
       " 'pulm',\n",
       " 'pulmonary',\n",
       " 'punctate',\n",
       " 'q',\n",
       " 'r',\n",
       " 'radiating',\n",
       " 'ranged',\n",
       " 'rapid',\n",
       " 'rashes',\n",
       " 'rate',\n",
       " 'ray',\n",
       " 'rbc',\n",
       " 're',\n",
       " 'recent',\n",
       " 'recommended',\n",
       " 'recorded',\n",
       " 'related',\n",
       " 'release',\n",
       " 'remaining',\n",
       " 'remember',\n",
       " 'renal',\n",
       " 'repeat',\n",
       " 'requested',\n",
       " 'responded',\n",
       " 'restarting',\n",
       " 'results',\n",
       " 'retired',\n",
       " 'return',\n",
       " 'revealed',\n",
       " 'reverse',\n",
       " 'reversed',\n",
       " 'review',\n",
       " 'reviewed',\n",
       " 'rhythm',\n",
       " 'right',\n",
       " 'rle',\n",
       " 'ros',\n",
       " 'rounded',\n",
       " 'rr',\n",
       " 'rt',\n",
       " 'rusb',\n",
       " 'rvr',\n",
       " 'sacral',\n",
       " 'saline',\n",
       " 'sample',\n",
       " 'sats',\n",
       " 'scan',\n",
       " 'scans',\n",
       " 'scattered',\n",
       " 'scheduled',\n",
       " 'scleral',\n",
       " 'sdh',\n",
       " 'sdhs',\n",
       " 'secondary',\n",
       " 'seen',\n",
       " 'seizure',\n",
       " 'seizures',\n",
       " 'senna',\n",
       " 'sensation',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'setting',\n",
       " 'several',\n",
       " 'severe',\n",
       " 'shortness',\n",
       " 'showed',\n",
       " 'sided',\n",
       " 'sides',\n",
       " 'sig',\n",
       " 'significant',\n",
       " 'signs',\n",
       " 'size',\n",
       " 'skin',\n",
       " 'slurring',\n",
       " 'sm',\n",
       " 'small',\n",
       " 'so',\n",
       " 'social',\n",
       " 'sodium',\n",
       " 'soft',\n",
       " 'some',\n",
       " 'sp',\n",
       " 'speaking',\n",
       " 'speech',\n",
       " 'spine',\n",
       " 'stable',\n",
       " 'start',\n",
       " 'started',\n",
       " 'status',\n",
       " 'stenosis',\n",
       " 'stethoscope',\n",
       " 'stitle',\n",
       " 'store',\n",
       " 'strength',\n",
       " 'strokes',\n",
       " 'study',\n",
       " 'subarachnoid',\n",
       " 'subdural',\n",
       " 'subdurals',\n",
       " 'succinate',\n",
       " 'suggested',\n",
       " 'suite',\n",
       " 'supratherapeutic',\n",
       " 'supratheraputic',\n",
       " 'surgical',\n",
       " 'sustained',\n",
       " 'swelling',\n",
       " 'symmetrical',\n",
       " 'symptoms',\n",
       " 'systems',\n",
       " 'systolic',\n",
       " 'tablet',\n",
       " 'tablets',\n",
       " 'take',\n",
       " 'taking',\n",
       " 'tarlov',\n",
       " 'team',\n",
       " 'telephone',\n",
       " 'temporal',\n",
       " 'tentorial',\n",
       " 'tested',\n",
       " 'tetracycline',\n",
       " 'they',\n",
       " 'thinners',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tired',\n",
       " 'tissue',\n",
       " 'tobacco',\n",
       " 'toes',\n",
       " 'tone',\n",
       " 'tongue',\n",
       " 'toprol',\n",
       " 'tortuous',\n",
       " 'touch',\n",
       " 'tract',\n",
       " 'transfer',\n",
       " 'transferred',\n",
       " 'trauma',\n",
       " 'tri',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'tylenol',\n",
       " 'ucx',\n",
       " 'ultrasound',\n",
       " 'un',\n",
       " 'unable',\n",
       " 'unchanged',\n",
       " 'underlying',\n",
       " 'unit',\n",
       " 'units',\n",
       " 'unknown',\n",
       " 'until',\n",
       " 'up',\n",
       " 'urean',\n",
       " 'urinary',\n",
       " 'urine',\n",
       " 'urobiln',\n",
       " 'uti',\n",
       " 'v',\n",
       " 'valve',\n",
       " 'vancomycin',\n",
       " 'ventricles',\n",
       " 'ventricular',\n",
       " 'vi',\n",
       " 'vii',\n",
       " 'visit',\n",
       " 'vital',\n",
       " 'vitamin',\n",
       " 'voice',\n",
       " 'volume',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'ward',\n",
       " 'warranted',\n",
       " 'wbc',\n",
       " 'weakness',\n",
       " 'week',\n",
       " 'weeks',\n",
       " 'well',\n",
       " 'when',\n",
       " 'who',\n",
       " 'widowed',\n",
       " 'will',\n",
       " 'within',\n",
       " 'without',\n",
       " 'worsening',\n",
       " 'x',\n",
       " 'xii',\n",
       " 'xr',\n",
       " 'xs',\n",
       " 'year',\n",
       " 'yeast',\n",
       " 'yellow',\n",
       " 'yo']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text = tokenizer_better(x_train[0])\n",
    "vect.fit(x_text)\n",
    "vect.transform(x_text).toarray().shape\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a vectorizer on the clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    "                 'is','patient','s','he','at','as','or','one','she','his','her','am',\n",
    "                 'were','you','pt','pm','by','be','had','your','this','date',\n",
    "                'from','there','an','that','p','are','have','has','h','but','o',\n",
    "                'namepattern','which','every','also','t','that']\n",
    "vect = CountVectorizer(max_features = 3000, tokenizer = tokenizer_better, stop_words = my_stop_words)\n",
    "# this could take a while\n",
    "X_train_counts = vect.fit_transform(x_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with adding tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1833, 3000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buidling the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8562091503267973"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_svm = Pipeline([\n",
    "     ('vect', CountVectorizer(lowercase = True, max_features = 4000, tokenizer = tokenizer_better,stop_words =my_stop_words)),\n",
    "     #('tfidf', TfidfTransformer()), #without this 0.856\n",
    "     ('svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),#0.83\n",
    "    ])\n",
    "\n",
    "\n",
    "text_svm.fit(x_train, y_train)\n",
    "\n",
    "predicted = text_svm.predict(x_test)\n",
    "np.mean(predicted == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
